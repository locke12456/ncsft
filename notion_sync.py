import os
import hashlib
import json
from pathlib import Path
from notion_client import Client
from datetime import datetime
from config import Config

class NotionSync:
    """Notion æª”æ¡ˆåŒæ­¥æ ¸å¿ƒé¡åˆ¥ (æ”¯æ´å¤šèªè¨€)"""
    
    def __init__(self, notion_token, parent_page_id):
        """
        åˆå§‹åŒ–åŒæ­¥å™¨
        
        Args:
            notion_token: Notion API token
            parent_page_id: çˆ¶é é¢ IDï¼ˆæª”æ¡ˆå°‡å»ºç«‹ç‚ºæ­¤é é¢çš„å­é é¢ï¼‰
        """
        self.notion = Client(auth=notion_token)
        self.parent_page_id = parent_page_id
        self.sync_cache = self._load_sync_cache()
        
    def scan_source_files(self, root_path, extensions=None):
        """
        æƒææŒ‡å®šè³‡æ–™å¤¾ä¸­çš„æ‰€æœ‰ç¨‹å¼ç¢¼æª”æ¡ˆ
        
        Args:
            root_path: æ ¹ç›®éŒ„è·¯å¾‘
            extensions: è¦æƒæçš„æª”æ¡ˆå‰¯æª”åæ¸…å–®ï¼ŒNone è¡¨ç¤ºæƒææ‰€æœ‰æ”¯æ´çš„é¡å‹
            
        Returns:
            list: ç¨‹å¼ç¢¼æª”æ¡ˆè·¯å¾‘æ¸…å–®
        """
        source_files = []
        root = Path(root_path).resolve()  # è§£æç‚ºçµ•å°è·¯å¾‘
        
        if not root.exists():
            raise ValueError(f"æŒ‡å®šè·¯å¾‘ä¸å­˜åœ¨: {root_path}")
        
        # å¦‚æœæ²’æœ‰æŒ‡å®šå‰¯æª”åï¼Œä½¿ç”¨æ‰€æœ‰æ”¯æ´çš„é¡å‹
        if extensions is None:
            extensions = Config.get_supported_extensions()
        
        print(f"é–‹å§‹æƒæç›®éŒ„: {root}")
        print(f"æ”¯æ´çš„æª”æ¡ˆé¡å‹: {', '.join(extensions)}")
        
        for ext in extensions:
            pattern = f"*{ext}"
            for file_path in root.rglob(pattern):
                # æª¢æŸ¥æ˜¯å¦åœ¨å¿½ç•¥æ¸…å–®ä¸­
                if Config.should_ignore_path(str(file_path)):
                    continue
                    
                source_files.append(file_path)
        
        # æŒ‰æª”æ¡ˆè·¯å¾‘æ’åºï¼Œç¢ºä¿ä¸€è‡´çš„è™•ç†é †åº
        source_files.sort()
        
        print(f"æƒæå®Œæˆï¼Œæ‰¾åˆ° {len(source_files)} å€‹ç¨‹å¼ç¢¼æª”æ¡ˆ")
        return source_files
    
    def get_file_hash(self, file_path):
        """
        è¨ˆç®—æª”æ¡ˆçš„ MD5 hash
        
        Args:
            file_path: æª”æ¡ˆè·¯å¾‘
            
        Returns:
            str: MD5 hash å­—ä¸²
        """
        try:
            with open(file_path, 'rb') as f:
                file_content = f.read()
                return hashlib.md5(file_content).hexdigest()
        except Exception as e:
            print(f"ç„¡æ³•è¨ˆç®—æª”æ¡ˆ hash {file_path}: {str(e)}")
            return None
    
    def get_file_size(self, file_path):
        """å–å¾—æª”æ¡ˆå¤§å°"""
        try:
            return os.path.getsize(file_path)
        except:
            return 0
    
    def create_or_update_subpage(self, file_path, project_root, force_update=False):
        """
        å»ºç«‹æˆ–æ›´æ–°æª”æ¡ˆçš„å­é é¢
        
        Args:
            file_path: æª”æ¡ˆè·¯å¾‘
            project_root: å°ˆæ¡ˆæ ¹ç›®éŒ„è·¯å¾‘
            force_update: æ˜¯å¦å¼·åˆ¶æ›´æ–°
            
        Returns:
            str|None: é é¢ ID æˆ– Noneï¼ˆå¦‚æœå¤±æ•—ï¼‰
        """
        file_hash = self.get_file_hash(file_path)
        if not file_hash:
            return None
            
        # ä¿®å¾©ç›¸å°è·¯å¾‘è¨ˆç®—å•é¡Œ
        try:
            project_root_path = Path(project_root).resolve()
            file_absolute_path = Path(file_path).resolve()
            relative_path = str(file_absolute_path.relative_to(project_root_path))
        except ValueError as e:
            # å¦‚æœ relative_to å¤±æ•—ï¼Œä½¿ç”¨æª”æ¡ˆåä½œç‚ºå‚™é¸
            print(f"è­¦å‘Šï¼šç„¡æ³•è¨ˆç®—ç›¸å°è·¯å¾‘ {file_path}ï¼Œä½¿ç”¨æª”æ¡ˆå: {e}")
            relative_path = file_path.name
        
        file_size = self.get_file_size(file_path)
        
        # æª¢æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°
        if not force_update and relative_path in self.sync_cache:
            cached_data = self.sync_cache[relative_path]
            if cached_data.get('hash') == file_hash:
                print(f"â­ï¸  è·³é {relative_path} (ç„¡è®Šæ›´)")
                return cached_data.get('page_id')
        
        # è®€å–æª”æ¡ˆå…§å®¹
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
        except UnicodeDecodeError:
            # å˜—è©¦å…¶ä»–ç·¨ç¢¼
            try:
                with open(file_path, 'r', encoding='gbk') as f:
                    content = f.read()
            except:
                print(f"âŒ ç„¡æ³•è®€å–æª”æ¡ˆ {file_path}: ç·¨ç¢¼å•é¡Œ")
                return None
        except Exception as e:
            print(f"âŒ ç„¡æ³•è®€å–æª”æ¡ˆ {file_path}: {str(e)}")
            return None
        
        # æª¢æŸ¥å…§å®¹é•·åº¦é™åˆ¶
        if len(content) > Config.MAX_CONTENT_LENGTH:
            content = content[:Config.MAX_CONTENT_LENGTH] + "\\n\\n... (æª”æ¡ˆéé•·ï¼Œå·²æˆªæ–·)"
        
        # æº–å‚™é é¢æ¨™é¡Œå’Œèªè¨€
        page_title = f"{file_path.name}"
        language = Config.get_language_for_extension(file_path.suffix)
        
        try:
            # æª¢æŸ¥é é¢æ˜¯å¦å·²å­˜åœ¨
            page_id = self.sync_cache.get(relative_path, {}).get('page_id')
            
            if page_id:
                # æ›´æ–°ç¾æœ‰å­é é¢
                try:
                    self.notion.pages.update(
                        page_id=page_id,
                        properties={
                            "title": [{
                                "text": {
                                    "content": page_title
                                }
                            }]
                        }
                    )
                    
                    # æ›´æ–°é é¢å…§å®¹
                    self._update_subpage_content(page_id, content, file_path, language)
                    print(f"ğŸ”„ æ›´æ–° {relative_path}")
                    
                except Exception as e:
                    print(f"æ›´æ–°é é¢å¤±æ•—ï¼Œå˜—è©¦é‡æ–°å»ºç«‹: {str(e)}")
                    page_id = None
            
            if not page_id:
                # å»ºç«‹æ–°çš„å­é é¢
                new_page = self.notion.pages.create(
                    parent={
                        "type": "page_id",
                        "page_id": self.parent_page_id
                    },
                    properties={
                        "title": [{
                            "text": {
                                "content": page_title
                            }
                        }]
                    }
                )
                
                page_id = new_page["id"]
                self._update_subpage_content(page_id, content, file_path, language)
                print(f"âœ… å»ºç«‹ {relative_path}")
            
            # æ›´æ–°å¿«å–
            self.sync_cache[relative_path] = {
                'page_id': page_id,
                'hash': file_hash,
                'last_sync': datetime.now().isoformat(),
                'file_size': file_size,
                'language': language
            }
            
            return page_id
            
        except Exception as e:
            print(f"âŒ åŒæ­¥å¤±æ•— {relative_path}: {str(e)}")
            return None
    
    def _update_subpage_content(self, page_id, content, file_path, language):
        """
        æ›´æ–°å­é é¢å…§å®¹

        Args:
            page_id: é é¢ ID
            content: æª”æ¡ˆå…§å®¹
            file_path: æª”æ¡ˆè·¯å¾‘
            language: ç¨‹å¼èªè¨€
        """
        try:
            # æ¸…é™¤ç¾æœ‰å…§å®¹
            children = self.notion.blocks.children.list(block_id=page_id)
            for block in children["results"]:
                try:
                    self.notion.blocks.delete(block_id=block["id"])
                except:
                    pass  # æŸäº› block å¯èƒ½ç„¡æ³•åˆªé™¤ï¼Œå¿½ç•¥éŒ¯èª¤
            
            # æ ¹æ“šæª”æ¡ˆé¡å‹é¸æ“‡é©ç•¶çš„åœ–ç¤º
            file_icons = {
                'c#': 'ğŸ”·',
                'python': 'ğŸ',
                'javascript': 'ğŸ“œ',
                'typescript': 'ğŸ“˜',
                'java': 'â˜•',
                'c++': 'âš¡',
                'c': 'ğŸ”§',
                'go': 'ğŸ”·',
                'rust': 'ğŸ¦€',
                'php': 'ğŸ˜',
                'ruby': 'ğŸ’',
                'swift': 'ğŸ•Šï¸',
                'kotlin': 'ğŸ¯'
            }
            
            icon = file_icons.get(language, 'ğŸ“„')
            
            # åŸºç¤å…§å®¹å€å¡Š
            blocks = [
                {
                    "object": "block",
                    "type": "heading_2",
                    "heading_2": {
                        "rich_text": [{
                            "type": "text", 
                            "text": {"content": f"{icon} {file_path.name}"}
                        }]
                    }
                },
                {
                    "object": "block",
                    "type": "paragraph",
                    "paragraph": {
                        "rich_text": [{
                            "type": "text", 
                            "text": {"content": f"ğŸ“ è·¯å¾‘: {str(file_path)}\nğŸ”¤ èªè¨€: {language.title()}\nğŸ“ å¤§å°: {len(content)} å­—å…ƒ"}
                        }]
                    }
                },
                {
                    "object": "block",
                    "type": "divider",
                    "divider": {}
                }
            ]
            
            # å¼·åˆ¶åˆ†å¡Šè™•ç†æ‰€æœ‰ç¨‹å¼ç¢¼å…§å®¹
            if len(content) > 0:
                # ä½¿ç”¨æ›´å°çš„å®‰å…¨å¡Šå¤§å°
                max_chunk_size = 1500  # é€²ä¸€æ­¥ç¸®å°åˆ° 1500 å­—å…ƒ
                
                # å°‡ç¨‹å¼ç¢¼æŒ‰è¡Œåˆ†å¡Š
                content_lines = content.split('\n')
                current_chunk_lines = []
                current_chunk_length = 0
                chunk_number = 1
                
                for line in content_lines:
                    line_length = len(line) + 1  # +1 for newline character
                    
                    # æª¢æŸ¥æ·»åŠ é€™è¡Œæ˜¯å¦æœƒè¶…éé™åˆ¶
                    if current_chunk_length + line_length > max_chunk_size and current_chunk_lines:
                        # å‰µå»ºç•¶å‰å¡Š
                        chunk_content = '\n'.join(current_chunk_lines)
                        
                        # æ·»åŠ å¡Šæ¨™é¡Œï¼ˆé™¤éæ˜¯ç¬¬ä¸€å€‹ä¸”åªæœ‰ä¸€å€‹å¡Šï¼‰
                        if chunk_number > 1 or len(content) > max_chunk_size:
                            blocks.append({
                                "object": "block",
                                "type": "heading_3",
                                "heading_3": {
                                    "rich_text": [{
                                        "type": "text", 
                                        "text": {"content": f"ğŸ“‹ ç¨‹å¼ç¢¼ (ç¬¬ {chunk_number} éƒ¨åˆ†)"}
                                    }]
                                }
                            })
                        
                        # æ·»åŠ ç¨‹å¼ç¢¼å€å¡Š
                        blocks.append({
                            "object": "block",
                            "type": "code",
                            "code": {
                                "rich_text": [{
                                    "type": "text", 
                                    "text": {"content": chunk_content}
                                }],
                                "language": language
                            }
                        })
                        
                        # é–‹å§‹æ–°çš„å¡Š
                        current_chunk_lines = [line]
                        current_chunk_length = line_length
                        chunk_number += 1
                    else:
                        current_chunk_lines.append(line)
                        current_chunk_length += line_length
                
                # æ·»åŠ æœ€å¾Œä¸€å€‹å¡Š
                if current_chunk_lines:
                    chunk_content = '\n'.join(current_chunk_lines)
                    
                    # æ·»åŠ å¡Šæ¨™é¡Œï¼ˆå¦‚æœæœ‰å¤šå€‹å¡Šï¼‰
                    if chunk_number > 1:
                        blocks.append({
                            "object": "block",
                            "type": "heading_3",
                            "heading_3": {
                                "rich_text": [{
                                    "type": "text", 
                                    "text": {"content": f"ğŸ“‹ ç¨‹å¼ç¢¼ (ç¬¬ {chunk_number} éƒ¨åˆ†ï¼Œå®Œ)"}
                                }]
                            }
                        })
                    
                    blocks.append({
                        "object": "block",
                        "type": "code",
                        "code": {
                            "rich_text": [{
                                "type": "text", 
                                "text": {"content": chunk_content}
                            }],
                            "language": language
                        }
                    })
            
            # åˆ†æ‰¹æ·»åŠ  blocks åˆ°é é¢
            batch_size = 100
            for i in range(0, len(blocks), batch_size):
                batch = blocks[i:i+batch_size]
                self.notion.blocks.children.append(block_id=page_id, children=batch)
            
        except Exception as e:
            print(f"æ›´æ–°é é¢å…§å®¹å¤±æ•—: {str(e)}")
    
    def sync_project(self, project_path, force_update=False, file_extensions=None):
        """
        åŒæ­¥æ•´å€‹å°ˆæ¡ˆ
        
        Args:
            project_path: å°ˆæ¡ˆè·¯å¾‘
            force_update: æ˜¯å¦å¼·åˆ¶æ›´æ–°æ‰€æœ‰æª”æ¡ˆ
            file_extensions: è¦åŒæ­¥çš„æª”æ¡ˆå‰¯æª”åæ¸…å–®ï¼ŒNone è¡¨ç¤ºæ‰€æœ‰æ”¯æ´çš„é¡å‹
        """
        try:
            # è§£æå°ˆæ¡ˆè·¯å¾‘ç‚ºçµ•å°è·¯å¾‘
            project_root = Path(project_path).resolve()
            
            # å¦‚æœæŒ‡å®šäº†ç‰¹å®šå‰¯æª”åï¼Œåªæƒæé‚£äº›é¡å‹
            source_files = self.scan_source_files(project_root, file_extensions)
            
            if not source_files:
                print("æœªæ‰¾åˆ°ä»»ä½•ç¬¦åˆæ¢ä»¶çš„ç¨‹å¼ç¢¼æª”æ¡ˆ")
                return
            
            print(f"\\né–‹å§‹åŒæ­¥ {len(source_files)} å€‹æª”æ¡ˆ...")
            print("=" * 60)
            
            # æŒ‰èªè¨€åˆ†çµ„çµ±è¨ˆ
            language_stats = {}
            success_count = 0
            
            for i, file_path in enumerate(source_files, 1):
                print(f"[{i}/{len(source_files)}] ", end="")
                
                if self.create_or_update_subpage(file_path, project_root, force_update):
                    success_count += 1
                    # çµ±è¨ˆèªè¨€é¡å‹
                    ext = file_path.suffix
                    language = Config.get_language_for_extension(ext)
                    language_stats[language] = language_stats.get(language, 0) + 1
            
            print("=" * 60)
            print(f"âœ¨ åŒæ­¥å®Œæˆ: {success_count}/{len(source_files)} å€‹æª”æ¡ˆæˆåŠŸåŒæ­¥")
            
            # é¡¯ç¤ºèªè¨€çµ±è¨ˆ
            if language_stats:
                print("\\nğŸ“Š æª”æ¡ˆé¡å‹çµ±è¨ˆ:")
                for lang, count in sorted(language_stats.items()):
                    print(f"   {lang.title()}: {count} å€‹æª”æ¡ˆ")
            
            # å„²å­˜å¿«å–
            self._save_sync_cache()
            
        except Exception as e:
            print(f"å°ˆæ¡ˆåŒæ­¥å¤±æ•—: {str(e)}")
    
    def sync_specific_language(self, project_path, language, force_update=False):
        """
        åŒæ­¥ç‰¹å®šç¨‹å¼èªè¨€çš„æª”æ¡ˆ
        
        Args:
            project_path: å°ˆæ¡ˆè·¯å¾‘
            language: ç¨‹å¼èªè¨€åç¨± (å¦‚ 'python', 'c#')
            force_update: æ˜¯å¦å¼·åˆ¶æ›´æ–°
        """
        # æ‰¾å‡ºå°æ‡‰çš„æª”æ¡ˆå‰¯æª”å
        extensions = []
        for ext, lang in Config.SUPPORTED_LANGUAGES.items():
            if lang.lower() == language.lower():
                extensions.append(ext)
        
        if not extensions:
            print(f"âŒ ä¸æ”¯æ´çš„ç¨‹å¼èªè¨€: {language}")
            print(f"æ”¯æ´çš„èªè¨€: {', '.join(set(Config.SUPPORTED_LANGUAGES.values()))}")
            return
        
        print(f"ğŸ¯ åŒæ­¥ {language.title()} æª”æ¡ˆ (å‰¯æª”å: {', '.join(extensions)})")
        self.sync_project(project_path, force_update, extensions)
    
    def _load_sync_cache(self):
        """è¼‰å…¥åŒæ­¥å¿«å–"""
        cache_file = Path(Config.CACHE_FILE)
        if cache_file.exists():
            try:
                with open(cache_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                print(f"è¼‰å…¥å¿«å–å¤±æ•—: {str(e)}")
                return {}
        return {}
    
    def _save_sync_cache(self):
        """å„²å­˜åŒæ­¥å¿«å–"""
        try:
            with open(Config.CACHE_FILE, 'w', encoding='utf-8') as f:
                json.dump(self.sync_cache, f, indent=2, ensure_ascii=False)
            print(f"ğŸ’¾ å¿«å–å·²å„²å­˜åˆ° {Config.CACHE_FILE}")
        except Exception as e:
            print(f"å„²å­˜å¿«å–å¤±æ•—: {str(e)}")
    
    def clean_deleted_files(self):
        """æ¸…ç†å·²åˆªé™¤æª”æ¡ˆçš„å¿«å–è¨˜éŒ„"""
        if not self.sync_cache:
            return
        
        to_remove = []
        for file_path in self.sync_cache.keys():
            if not Path(file_path).exists():
                to_remove.append(file_path)
        
        for file_path in to_remove:
            del self.sync_cache[file_path]
            print(f"ğŸ—‘ï¸  ç§»é™¤å·²åˆªé™¤æª”æ¡ˆçš„å¿«å–: {file_path}")
        
        if to_remove:
            self._save_sync_cache()
    
    def get_project_stats(self, project_path):
        """å–å¾—å°ˆæ¡ˆçµ±è¨ˆè³‡è¨Š"""
        project_root = Path(project_path).resolve()
        source_files = self.scan_source_files(project_root)
        
        stats = {
            'total_files': len(source_files),
            'languages': {},
            'synced_files': 0,
            'unsynced_files': 0
        }
        
        for file_path in source_files:
            ext = file_path.suffix
            language = Config.get_language_for_extension(ext)
            stats['languages'][language] = stats['languages'].get(language, 0) + 1
            
            # æª¢æŸ¥åŒæ­¥ç‹€æ…‹
            try:
                relative_path = str(file_path.relative_to(project_root))
            except ValueError:
                relative_path = file_path.name
                
            if relative_path in self.sync_cache:
                stats['synced_files'] += 1
            else:
                stats['unsynced_files'] += 1
        
        return stats